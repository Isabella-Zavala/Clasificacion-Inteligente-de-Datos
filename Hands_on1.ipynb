{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Isabella Alessandra Zavala Y Petriciolli Romo 219556875*\n",
        "\n",
        "**Clasificación Inteligente de Datos**"
      ],
      "metadata": {
        "id": "k-3qTbyyizqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on 1 Perceptron\n",
        "Este Notebook presenta un tutorial completo sobre el algoritmo Perceptrón, uno de los clasificadores lineales más fundamentales en el campo del Machine Learning. El objetivo es comprender sus bases teóricas e implementar su funcionamiento práctico utilizando la librería scikit-learn de Python."
      ],
      "metadata": {
        "id": "TJ-0cdXQZkmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vr79pFPziwHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1  Fundamentos de la técnica**\n",
        "\n",
        "El Perceptrón, ideado por Frank Rosenblatt en 1957, es el primer algoritmo de red neuronal artificial y un tipo de clasificador lineal. Su principal función es aprender a clasificar patrones de entrada en dos clases distintas (problema de clasificación binaria) a través de un límite de decisión lineal.\n",
        "\n",
        "El principio fundamental es simple: si los datos de entrenamiento son linealmente separables (es decir, se puede trazar una línea, plano o hiperplano para separar perfectamente las dos clases), el algoritmo del Perceptrón está garantizado para converger y encontrar esa separación en un número finito de pasos.\n",
        "\n",
        "El Perceptrón simula la operación de una sola neurona biológica, recibiendo múltiples entradas, ponderándolas, sumándolas, y pasando el resultado a través de una función de activación (generalmente la función escalón, o step function) para producir una salida binaria ($\\{+1, -1\\}$ o $\\{0, 1\\}$)."
      ],
      "metadata": {
        "id": "lkmckLaqaCcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Modelo Matemático del Perceptrón**\n",
        "\n",
        "\n",
        "El Perceptrón opera en dos fases principales: la combinación lineal y la función de activación.\n",
        "\n",
        "Combinación Lineal (Cálculo del Potencial de Entrada)\n",
        "\n",
        "Para un vector de entrada $\\mathbf{x}$ con $n$ características, el potencial de entrada ($z$) se calcula como la suma ponderada de las entradas más un término de polarización o sesgo ($b$):\n",
        "\n",
        "$$z = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b\n",
        "$$Esto se expresa de manera compacta usando producto punto:\n",
        "\n",
        "$$z = \\mathbf{w} \\cdot \\mathbf{x} + b\n",
        "$$Donde:\n",
        "\n",
        "  * $\\mathbf{w}$ es el vector de pesos (weights).\n",
        "  * $\\mathbf{x}$ es el vector de entradas (features).\n",
        "  * $b$ es el sesgo (bias).\n",
        "\n",
        "#### Función de Activación (Predicción)\n",
        "\n",
        "El resultado $z$ se pasa a través de una función de activación (la función escalón) para obtener la predicción binaria $\\hat{y}$:$$\n",
        "\n",
        "\\hat{y} = \\text{sign}(z) = \\begin{cases} +1 & \\text{si } z \\geq 0 \\ -1 & \\text{si } z < 0 \\end{cases}\n",
        "$$#### Regla de Aprendizaje (Actualización de Pesos)\n",
        "\n",
        "El algoritmo aprende iterativamente. Si la predicción $\\hat{y}$ es incorrecta para un patrón $x^{(i)}$ con etiqueta real $y^{(i)}$, los pesos se ajustan mediante la siguiente regla (conocida como la Regla del Perceptrón):\n",
        "\n",
        "$$\\mathbf{w}{\\text{nuevo}} = \\mathbf{w}{\\text{anterior}} + \\eta \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\cdot \\mathbf{x}^{(i)}\n",
        "$$$$\n",
        "b_{\\text{nuevo}} = b_{\\text{anterior}} + \\eta \\cdot (y^{(i)} - \\hat{y}^{(i)})\n",
        "$$Donde:\n",
        "\n",
        "$\\eta$ (eta) es la tasa de aprendizaje (learning rate), un valor pequeño que controla la magnitud del ajuste (generalmente $\\eta \\in (0, 1]$).\n",
        "\n",
        "$(y^{(i)} - \\hat{y}^{(i)})$ es el error. Dado que las salidas son $+1$ o $-1$, el error solo puede ser $2$, $-2$, o $0$."
      ],
      "metadata": {
        "id": "ngJ7Sh-acUk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Importación de librerías necesarias\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "azhNYNAo13JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carga del dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data[:, [0, 2]]  # Usamos largo del sépalo y largo del pétalo\n",
        "y = iris.target\n",
        "\n",
        "# Para simplificar, seleccionamos solo dos clases: Setosa (0) y Versicolor (1)\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n"
      ],
      "metadata": {
        "id": "1foS6xMM1_iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. División de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(X_train)}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {len(X_test)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_U64zAH2Dxs",
        "outputId": "02bf043e-bd19-494b-f34e-6f47e39f5b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 70\n",
            "Tamaño del conjunto de prueba: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Estandarización de las características\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_std = scaler.transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "eTHuJsOo2Fui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Creación y entrenamiento del modelo Perceptrón\n",
        "ppn = Perceptron(eta0=0.1, random_state=1)\n",
        "ppn.fit(X_train_std, y_train)\n",
        "\n",
        "print(\"\\n--- Entrenamiento Completado ---\")\n",
        "print(f\"Pesos aprendidos (w): {ppn.coef_}\")\n",
        "print(f\"Sesgo aprendido (b): {ppn.intercept_}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkZkuGSA2JRs",
        "outputId": "2bb8e70a-2b64-4139-c601-efb2f13079b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Entrenamiento Completado ---\n",
            "Pesos aprendidos (w): [[-0.00803205  0.19536002]]\n",
            "Sesgo aprendido (b): [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Función para clasificar nuevos patrones\n",
        "def clasificar_patron(modelo, estandarizador, caracteristicas):\n",
        "    patron_escalado = estandarizador.transform([caracteristicas])\n",
        "    prediccion = modelo.predict(patron_escalado)\n",
        "    clase_predicha = \"Iris Setosa (Clase 0)\" if prediccion[0] == 0 else \"Iris Versicolor (Clase 1)\"\n",
        "\n",
        "    print(f\"\\nCaracterísticas de entrada: {caracteristicas}\")\n",
        "    print(f\"Patrón estandarizado: {patron_escalado[0]}\")\n",
        "    print(f\"Predicción del modelo: {clase_predicha}\")\n",
        "    return prediccion[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "I--Ri3jx2LVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Prueba de patrones\n",
        "patron_setosa = [5.0, 1.5]\n",
        "print(\"\\n--- Clasificando Patrón Típico Setosa ---\")\n",
        "clasificar_patron(ppn, scaler, patron_setosa)\n",
        "\n",
        "patron_versicolor = [6.0, 4.5]\n",
        "print(\"\\n--- Clasificando Patrón Típico Versicolor ---\")\n",
        "clasificar_patron(ppn, scaler, patron_versicolor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIYcpRnK2NCj",
        "outputId": "8dabf567-4761-4334-9f71-71d3c597f9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Clasificando Patrón Típico Setosa ---\n",
            "\n",
            "Características de entrada: [5.0, 1.5]\n",
            "Patrón estandarizado: [-0.76182782 -0.94135169]\n",
            "Predicción del modelo: Iris Setosa (Clase 0)\n",
            "\n",
            "--- Clasificando Patrón Típico Versicolor ---\n",
            "\n",
            "Características de entrada: [6.0, 4.5]\n",
            "Patrón estandarizado: [0.94194047 1.12647106]\n",
            "Predicción del modelo: Iris Versicolor (Clase 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluación del modelo\n",
        "y_pred = ppn.predict(X_test_std)\n",
        "print(f\"\\nEtiquetas Reales (primeros 10):   {y_test[:10]}\")\n",
        "print(f\"Etiquetas Predichas (primeros 10): {y_pred[:10]}\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_porcentaje = accuracy * 100\n",
        "\n",
        "print(f\"\\n--- Resultados de la Evaluación ---\")\n",
        "print(f\"Muestras clasificadas incorrectamente: {(y_test != y_pred).sum()} de {len(y_test)}\")\n",
        "print(f\"Accuracy del modelo en el conjunto de prueba: {accuracy:.4f} ({accuracy_porcentaje:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_cGKTa_2On5",
        "outputId": "73fbfc99-c7ed-4297-e270-5a4aba650cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etiquetas Reales (primeros 10):   [1 1 0 0 0 1 1 1 0 0]\n",
            "Etiquetas Predichas (primeros 10): [1 1 0 0 0 1 1 1 0 0]\n",
            "\n",
            "--- Resultados de la Evaluación ---\n",
            "Muestras clasificadas incorrectamente: 0 de 30\n",
            "Accuracy del modelo en el conjunto de prueba: 1.0000 (100.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bibliografía**\n",
        "* Rosenblatt, F. (1958). The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain. *Psychological Review*, 65(6), 386–408.\n",
        "* Géron, A. (2022). *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* (3rd ed.). O'Reilly Media. (Capítulo 4: Training Models).\n",
        "* Scikit-learn documentation: `sklearn.linear_model.Perceptron`. https://ask.un.org/faq?gid=605&qid=19478"
      ],
      "metadata": {
        "id": "MYv6Ejem2Uoi"
      }
    }
  ]
}